# ğŸ ETL Pipeline - Le Mans 24h Race Data Analysis

[![Python](https://img.shields.io/badge/Python-3.13-blue.svg)](https://www.python.org/downloads/)
[![Pandas](https://img.shields.io/badge/Pandas-2.3.2-green.svg)](https://pandas.pydata.org/)
[![PySpark](https://img.shields.io/badge/PySpark-3.5.0-red.svg)](https://spark.apache.org/)
[![Seaborn](https://img.shields.io/badge/Seaborn-0.12.2-orange.svg)](https://seaborn.pydata.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

Un pipeline ETL completo y modular para procesar y visualizar datos histÃ³ricos de las 24 Horas de Le Mans, con capacidades avanzadas de anÃ¡lisis y generaciÃ³n automÃ¡tica de grÃ¡ficos. Incluye implementaciones tanto en Pandas como en PySpark para manejo eficiente de datasets de cualquier tamaÃ±o.

## ğŸ“‹ Tabla de Contenidos

- [ğŸ¯ CaracterÃ­sticas](#-caracterÃ­sticas)
- [ğŸ—ï¸ Arquitectura](#ï¸-arquitectura)
- [ğŸš€ InstalaciÃ³n](#-instalaciÃ³n)
- [ğŸ’» Uso](#-uso)
- [ğŸ“Š Visualizaciones](#-visualizaciones)
- [ğŸ“ Estructura del Proyecto](#-estructura-del-proyecto)
- [ğŸ”§ ConfiguraciÃ³n](#-configuraciÃ³n)
- [ğŸ“ˆ Datos](#-datos)
- [ğŸ¤ Contribuir](#-contribuir)
- [ğŸ“„ Licencia](#-licencia)

## ğŸ¯ CaracterÃ­sticas

### âœ¨ Pipeline ETL Completo
- **ğŸ”„ ExtracciÃ³n**: Ingesta automÃ¡tica de datos CSV desde Kaggle
- **âš™ï¸ TransformaciÃ³n**: Limpieza, normalizaciÃ³n y generaciÃ³n de campos calculados
- **ğŸ’¾ Carga**: Persistencia dual en SQLite y CSV para mÃ¡xima compatibilidad
- **ğŸ“Š VisualizaciÃ³n**: GeneraciÃ³n automÃ¡tica de anÃ¡lisis grÃ¡ficos con Seaborn
- **âš¡ Procesamiento Dual**: Implementaciones en Pandas y PySpark para diferentes escalas de datos

### ğŸ¨ AnÃ¡lisis Visual Avanzado
- **AnÃ¡lisis de Velocidad**: EvoluciÃ³n temporal y categorizaciÃ³n por rendimiento
- **AnÃ¡lisis de Resistencia**: Correlaciones entre vueltas y eficiencia
- **AnÃ¡lisis Temporal**: Progreso tecnolÃ³gico a travÃ©s de las dÃ©cadas
- **Dashboard Resumen**: Vista consolidada con mÃ©tricas clave

### ğŸ—ï¸ Arquitectura Modular
- **SeparaciÃ³n clara de responsabilidades** entre Extract, Transform, Load y Visualize
- **ConfiguraciÃ³n centralizada** para fÃ¡cil mantenimiento
- **Logging detallado** con indicadores visuales (emojis)
- **Manejo robusto de errores** con fallbacks automÃ¡ticos

### âš¡ Capacidades de PySpark
- **Procesamiento distribuido** para datasets masivos (> 1GB)
- **OptimizaciÃ³n automÃ¡tica** de consultas y transformaciones
- **Escalabilidad horizontal** en clusters de mÃºltiples nodos
- **Compatibilidad total** con el pipeline ETL existente
- **Rendimiento superior** para operaciones complejas de big data

## ğŸ—ï¸ Arquitectura

```
ProyectoETL-sports/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ Extract/          # ğŸ“¥ MÃ³dulo de extracciÃ³n
â”‚   â”‚   â”œâ”€â”€ SportsExtract.py
â”‚   â”‚   â””â”€â”€ Files/        # ğŸ“‚ Datos fuente
â”‚   â”‚       â””â”€â”€ data.csv
â”‚   â”œâ”€â”€ Transform/        # âš™ï¸ MÃ³dulo de transformaciÃ³n
â”‚   â”‚   â””â”€â”€ SportsTransformer.py
â”‚   â”œâ”€â”€ Load/            # ğŸ’¾ MÃ³dulo de carga
â”‚   â”‚   â””â”€â”€ SportsLoader.py
â”‚   â”œâ”€â”€ Visualize/       # ğŸ“Š MÃ³dulo de visualizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ SportsVisualizer.py
â”‚   â”‚   â””â”€â”€ Charts/      # ğŸ–¼ï¸ GrÃ¡ficas generadas
â”‚   â”œâ”€â”€ Config/          # âš™ï¸ ConfiguraciÃ³n
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â””â”€â”€ Output/          # ğŸ“¤ Resultados finales
â”‚       â”œâ”€â”€ sports_data.db              # Base de datos SQLite (Pandas)
â”‚       â”œâ”€â”€ sports_data_processed.csv   # CSV procesado (Pandas)
â”‚       â”œâ”€â”€ sports_data_spark.db        # Base de datos SQLite (Spark)
â”‚       â””â”€â”€ sports_data_spark.csv       # CSV procesado (Spark)
â”œâ”€â”€ main.py              # ğŸš€ Pipeline ETL principal (Pandas)
â”œâ”€â”€ mainV.2.py          # ğŸ“Š Script de visualizaciÃ³n
â”œâ”€â”€ spark_main.py       # âš¡ Pipeline ETL con Apache Spark
â””â”€â”€ requirements.txt     # ğŸ“¦ Dependencias
```

## ğŸš€ InstalaciÃ³n

### Prerrequisitos
- Python 3.13+
- Git

### 1. Clonar el repositorio
```bash
git clone https://github.com/MiguelBonilla-sys/ProyectoETL---sports.git
cd ProyectoETL---sports
```

### 2. Crear entorno virtual
```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# Linux/Mac
source .venv/bin/activate
```

### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 4. Configurar datos
Descarga el dataset desde [Kaggle](https://www.kaggle.com/datasets/erykwitkowski/lemans-24h-race-winners) y colÃ³calo en:
```
app/Extract/Files/data.csv
```

## ğŸ’» Uso

### ğŸš€ Pipeline ETL Completo (Pandas)
```bash
python main.py
```
**DescripciÃ³n**: Script principal que ejecuta el pipeline ETL completo usando Pandas para procesar datos de Le Mans.
- **ExtracciÃ³n**: Lee datos CSV desde `app/Extract/Files/data.csv`
- **TransformaciÃ³n**: Limpia, normaliza y agrega campos calculados (dÃ©cadas, categorÃ­as de velocidad/resistencia)
- **Carga**: Guarda resultados en SQLite (`sports_data.db`) y CSV (`sports_data_processed.csv`)
- **Salida**: Proporciona estadÃ­sticas detalladas del proceso y tiempo de ejecuciÃ³n

### ğŸ“Š Solo VisualizaciÃ³n
```bash
python mainV.2.py
```
**DescripciÃ³n**: Script especializado para generar visualizaciones desde datos ya procesados.
- **Prerrequisito**: Requiere ejecutar `main.py` primero para crear la base de datos
- **Funcionalidad**: Genera 4 tipos de anÃ¡lisis grÃ¡ficos (velocidad, resistencia, temporal, dashboard)
- **Salida**: Guarda grÃ¡ficas en formato PNG en `app/Visualize/Charts/`
- **ValidaciÃ³n**: Verifica automÃ¡ticamente que la base de datos existe antes de proceder

### âš¡ Pipeline ETL con PySpark
```bash
python spark_main.py
```
**DescripciÃ³n**: VersiÃ³n alternativa del pipeline ETL usando PySpark para procesamiento distribuido.
- **TecnologÃ­a**: Utiliza PySpark (Python API de Apache Spark) para manejo de big data
- **Proceso**: Mismo flujo ETL pero optimizado para datasets mÃ¡s grandes
- **Salida**: Genera `sports_data_spark.csv` y `sports_data_spark.db`
- **Ventajas**: Mejor rendimiento para datasets masivos y procesamiento paralelo

### ğŸ”„ ComparaciÃ³n de Scripts Main

| Script | TecnologÃ­a | Uso Recomendado | Salida |
|--------|------------|-----------------|---------|
| `main.py` | Pandas | Datasets pequeÃ±os-medianos (< 1GB) | `sports_data.db`, `sports_data_processed.csv` |
| `mainV.2.py` | Pandas + Seaborn | Solo visualizaciÃ³n (requiere datos procesados) | GrÃ¡ficas PNG en `Charts/` |
| `spark_main.py` | PySpark | Datasets grandes (> 1GB) o procesamiento distribuido | `sports_data_spark.db`, `sports_data_spark.csv` |

### ğŸ“‹ Flujo de Trabajo Recomendado

1. **Para anÃ¡lisis bÃ¡sico**: `python main.py` â†’ `python mainV.2.py`
2. **Para big data**: `python spark_main.py` â†’ `python mainV.2.py`
3. **Solo visualizaciÃ³n**: `python mainV.2.py` (si ya tienes datos procesados)

### Ejemplo de salida:
```
ğŸ ETL PIPELINE - DATOS DEPORTIVOS LE MANS ğŸ
============================================================

==================== PASO 1: EXTRACCIÃ“N DE DATOS ====================
ğŸ“‚ Archivo fuente: app\Extract\Files\data.csv
âœ… ExtracciÃ³n exitosa:
   ğŸ“Š Filas extraÃ­das: 229
   ğŸ“‹ Columnas: 15
   ğŸ“… Rango de aÃ±os: 1923 - 2023

==================== PASO 2: TRANSFORMACIÃ“N DE DATOS ====================
ğŸš€ INICIANDO TRANSFORMACIÃ“N DE DATOS
ğŸ“Š Iniciando limpieza de datos...
âœ… Filas finales despuÃ©s de limpieza: 227
ğŸ”§ Normalizando datos...
âœ… Datos normalizados correctamente
â• Agregando campos calculados...
âœ… Campos calculados agregados: Decade, Speed_Category, Endurance_Category

==================== PASO 3: CARGA DE DATOS ====================
ğŸ’¾ Guardando en base de datos SQLite...
âœ… Datos guardados en la base de datos SQLite
ğŸ’¾ Guardando CSV de respaldo...
âœ… Carga completada exitosamente
```

## ğŸ“Š Visualizaciones

El mÃ³dulo de visualizaciÃ³n genera 4 tipos de anÃ¡lisis:

### 1. ğŸƒâ€â™‚ï¸ AnÃ¡lisis de Velocidad (`speed_analysis.png`)
- DistribuciÃ³n por categorÃ­as de velocidad
- EvoluciÃ³n temporal de velocidades promedio
- Box plots por dÃ©cada
- Histograma de distribuciÃ³n

### 2. ğŸ AnÃ¡lisis de Resistencia (`endurance_trends.png`)
- CategorizaciÃ³n por resistencia (vueltas)
- CorrelaciÃ³n vueltas vs velocidad
- EvoluciÃ³n de vueltas promedio
- AnÃ¡lisis de eficiencia (Km/vuelta)

### 3. â° AnÃ¡lisis Temporal (`temporal_analysis.png`)
- Participantes por dÃ©cada
- Diversidad de equipos
- Progreso tecnolÃ³gico
- Heatmap de categorÃ­as

### 4. ğŸ“ˆ Dashboard Resumen (`summary_dashboard.png`)
- EstadÃ­sticas generales
- Top 10 equipos
- Timeline de participaciones
- MÃ©tricas consolidadas

## ğŸ“ Estructura del Proyecto

### MÃ³dulos Principales

#### ğŸ”„ Extract (`app/Extract/`)
- **`SportsExtract.py`**: Clase `Extractor` para lectura de archivos CSV
- **`Files/`**: Directorio para datos fuente

#### âš™ï¸ Transform (`app/Transform/`)
- **`SportsTransformer.py`**: Clase `SportsTransformer` con lÃ³gica especÃ­fica:
  - Limpieza y normalizaciÃ³n de datos
  - GeneraciÃ³n de campos calculados (dÃ©cadas, categorÃ­as, eficiencia)
  - ValidaciÃ³n y estadÃ­sticas

#### ğŸ’¾ Load (`app/Load/`)
- **`SportsLoader.py`**: Clase `Loader` con persistencia dual:
  - SQLite (principal)
  - CSV (respaldo)

#### ğŸ“Š Visualize (`app/Visualize/`)
- **`SportsVisualizer.py`**: Clase `SportsVisualizer` para anÃ¡lisis grÃ¡fico
- **`Charts/`**: Directorio de grÃ¡ficas generadas

#### âš™ï¸ Config (`app/Config/`)
- **`config.py`**: ConfiguraciÃ³n centralizada de rutas y parÃ¡metros

## ğŸ”§ ConfiguraciÃ³n

Edita `app/Config/config.py` para personalizar:

```python
class Config:
    # Rutas de entrada
    INPUT_PATH = r'app\Extract\Files\data.csv'
    
    # Rutas de salida
    OUTPUT_DIR = r'app\Output'
    SQLITE_DB_PATH = r'app\Output\sports_data.db'
    CSV_OUTPUT_PATH = r'app\Output\sports_data_processed.csv'
    
    # VisualizaciÃ³n
    CHARTS_OUTPUT_DIR = r'app\Visualize\Charts'
    CHART_THEMES = 'whitegrid'
    
    # CategorizaciÃ³n
    SPEED_CATEGORIES = {
        'bins': [0, 100, 150, 200, float('inf')],
        'labels': ['Slow', 'Medium', 'Fast', 'Very Fast']
    }
```

## ğŸ“ˆ Datos

### Fuente
**Dataset**: [Le Mans 24h Race Winners](https://www.kaggle.com/datasets/erykwitkowski/lemans-24h-race-winners)

### Schema de Datos Esperado
```
Year, Drivers, Class, Team, Car, Tyre, Laps, Km, Mi, Series, 
Driver_nationality, Team_nationality, Average_speed_kmh, 
Average_speed_mph, Average_lap_time
```

### Campos Calculados Generados
- **`Decade`**: AgrupaciÃ³n temporal (1920, 1930, etc.)
- **`Speed_Category`**: Slow, Medium, Fast, Very Fast
- **`Endurance_Category`**: Short, Medium, Long, Ultra Long
- **`Km_per_Lap`**: MÃ©trica de eficiencia

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

### Convenciones del Proyecto
- Usa el patrÃ³n de logging con emojis existente
- MantÃ©n la separaciÃ³n modular ETL
- Documenta nuevas transformaciones
- Sigue el patrÃ³n de manejo de errores establecido

## ğŸ› ï¸ Desarrollo

### Agregar Nuevas Transformaciones
```python
# En SportsTransformer.py
def new_transformation(self):
    print("ğŸ”§ Aplicando nueva transformaciÃ³n...")
    # Tu lÃ³gica aquÃ­
    print("âœ… TransformaciÃ³n completada")
    return self.df
```

### Agregar Nuevas Visualizaciones
```python
# En SportsVisualizer.py
def create_new_analysis(self):
    print("ğŸ“Š Generando nuevo anÃ¡lisis...")
    # Tu cÃ³digo de visualizaciÃ³n
    output_path = os.path.join(self.output_dir, 'new_analysis.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… Nuevo anÃ¡lisis guardado en: {output_path}")
```

## ğŸ“Š MÃ©tricas del Proyecto

- **LÃ­neas de cÃ³digo**: ~800
- **Cobertura de tests**: En desarrollo
- **Tiempo de ejecuciÃ³n**: ~10-15 segundos
- **Formatos de salida**: SQLite, CSV, PNG

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - mira el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ‘¨â€ğŸ’» Autor

**Miguel Bonilla** - [@MiguelBonilla-sys](https://github.com/MiguelBonilla-sys)

---

â­ **Â¡Dale una estrella si este proyecto te fue Ãºtil!**